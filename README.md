Automatic Gesture Recognition in Infants
========================================

This repository hosts the implementation of a gesture recognition model designed to analyze infant movements in video footage. 
The project aims to support research into early language development by providing a tool for identifying and interpreting 
infant gestures. This research was conducted as part of my Master's thesis in Artificial Intelligence at Utrecht University.

Features
--------
- Pre-trained Gesture Recognition Model: A machine learning model capable of detecting and classifying gestures in video data.
- Video Preprocessing Utilities: Scripts for preparing video input for the model.
- Evaluation Tools: Metrics and visualization methods to assess the model's performance.

Getting Started
---------------
1. **Clone the Repository**:
```bash
git clone https://github.com/your-username/infant-gesture-recognition.git cd infant-gesture-recognition
cd infant-gesture-recognition
```
2. **Install Dependencies**: Ensure you have Python installed, then use the following command:
```bash
pip install -r requirements.txt
```
3. **Load the Model**: The pre-trained model can be downloaded from ...
4. **Run the Model**: 
```bash
python run_model.py --input_path <path_to_video>
```

Future Work
-----------
This project is a foundation for further exploration of gesture recognition and its implications for language development 
research. Feel free to contribute, raise issues, or suggest enhancements!
